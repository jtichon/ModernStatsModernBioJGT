---
title: "Class 3 Summary"
author: "Jenna G. Tichon"
date: "07/10/2019"
output:
  pdf_document:
    includes:
      in_header: header.tex
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(vcd)
```

## 2.3 A simple Example of Statistical Modeling

This is a process for taking real data and trying to decide which distribution we should set it to.
```{r}
load(here("data", "e100.RData"))

#remove outlier to make dataset easier to work with
e99 = e100[-which.max(e100)]

#see picture of distribution to try to decide distribution
barplot(table(e99), space = 0.8, col = "chartreuse")

#Using vcd library, create theoretical fit of data set to poisson
gf1 = goodfit( e99, "poisson")

#The rootogram shifts the barplot to match theoretical values to show how far off you are
rootogram(gf1, xlab = "", rect_gp = gpar(fill = "chartreuse"))
```

\rtip{\texttt{goodfit} takes in "poisson", "binomial", "nbinomial"}

### Q2.1

Generate 100 random poissons with $\lambda=0.5$ to test out rootogram

```{r}
pois.100<-rpois(100,0.5)
gf2 = goodfit(pois.100, "poisson")
rootogram(gf2, xlab="", rect_gp = gpar(fill = "chartreuse"))
```

For the **MLE** we are looking for the most likely parameter based on the observed data.

```{r}
table(e100)
table(rpois(100,3))
```

Comparing our dataset to a Poisson 3 obviously shows that 3 would be a bad parameter estimate

### Q2.2

Given that we have 58 0's, 34 1's, and 7 2's, what's the probability of that happening given they are Poisson $m$?

\[P(0)^{58}\times P(1)^{34}\times P(2)^7 \times P(7)^1\]

for $m=3$ this is:

```{r}
#Side Note This gives individual probabilities
dpois(c(0,1,2,7),lambda = 3)^(c(58, 34, 7, 1))

#the Prod function gives us the product
prod(dpois(c(0,1,2,7),lambda = 3)^(c(58, 34, 7, 1)))
```
<<<<<<< HEAD

Which is decidedly super unlikely. 

### Q2.3

My Function to try different $m$ values and ascertain the likelihood of the data given that they are poisson $m$.

```{r}
#Function for trying different m's
pois100prob<-function(m){
prod(dpois(c(0,1,2,7),lambda = m)^(c(58, 34, 7, 1)))
}

pois100prob(0)
pois100prob(1)
pois100prob(2)
pois100prob(0.4)
```

Text's function to find out the log likelihood of various $m$ values to find the max:
```{r}
loglikelihood = function(lambda, data = e100){
sum(log(dpois(data,lambda)))
}
```

Note the sum of the logs of the likelihood is maximized when the product of the likelihoods is.

Use this function to evaluate for a series of lambdas:

```{r}
lambdas = seq(0.05, 0.95, length = 100)
loglik = vapply(lambdas, loglikelihood, numeric(1))
plot(lambdas, loglik, type = "l", col = "red", ylab = "", lwd = 2, xlab = expression(lambda))
m0 = mean(e100)
abline(v = m0, col = "blue", lwd = 2)
abline(h = loglikelihood(m0), col = "purple", lwd = 2)
m0
```

\rtip{ vapply applies the loglikelihood function to all of the elements of lambdas. numeric(1) tells it that it's returning a single numeric value}

Good fit has a shortcut for this:

```{r}
gf = goodfit(e100, "poisson")
names(gf)
gf$par
```

The outputs are:

  - *observed* : observed frequencies
  - *count* : corresponding counts
  - *fitted* : expected frequencies (maximum likelihood)
  - *type* : distribution being fitted
  - *method*: fitting method: "ML", "MinChisq", "fixed"
  - *df* : degrees of freedom
  - *par* : named list of parameter
  
Redoing the rootogram using 0.55:

```{r}
pois.100<-rpois(100,0.55)
gf2 = goodfit(pois.100, "poisson")
rootogram(gf2, xlab="", rect_gp = gpar(fill = "chartreuse"))
```

### Q2.6 

Known distributions allow us to not ``reinvent the wheel'' and reuse methods without rederiving results for each individual data set.

## Binomial Distributions and maximum likelihood

Looking at loglikelihood of binomial. Here's an example dataset:

```{r}
cb<-c(rep(0,110), rep(1,10))
table(cb)
```

We'd expect the maximum likelihood value to be 10/110=`r 10/110`

We can test this out using R
```{r}
probs = seq(0, 0.3, by = 0.005)
likelihood = dbinom(sum(cb), prob = probs, size = length(cb))
plot(probs, likelihood, pch = 16, xlab = "probability of success", ylab = "likelihood", cex=0.6)
probs[which.max(likelihood)]
```

We can find the loglikelihood function for binomial as:

```{r}
loglikelihood.binom = function(theta, n = 300, k = 40){
  115 + k * log(theta) + (n - k) * log(1 - theta)
}

thetas = seq(0, 1, by = 0.001)
plot(thetas, loglikelihood.binom(thetas), xlab = expression(theta), 
     ylab = expression(paste("log f(", theta, " | y")), type = "l")
```

\rtip{\red{WHAT DOES EXPRESSION DO?}}

**NB**: The diagram is flat near the max. This implies that a Bayesian might suggest that the value of $\theta$ is something random in a range of those likely values.

## 2.5 More boxes: multinomial data

\biotip{Four types of moecules in DNA: A - adenine, C - cytosine, G - guanine, T - thymine. A and G are purines and C and T are pyrimidines}

Looking at one DNA sequence
```{r}
library("Biostrings")
here("data", "e100.RData")
staph = readDNAStringSet(here("data","staphsequence.ffn.txt"), "fasta")
staph[1]
letterFrequency(staph[[1]], letters = "ACGT", OR = 0)
```
\rtip{The doublebrackets around the 1 pulls out the entire 1st sequence. Single brakets just gives the whole mess of data because staph is only one element long.}

### Q 2.9 

\alert{Reread this}
*Following a similar procedure as in Exercise 1.8, test whether the nucleotides are equally distributed across the four nucleotides for the first gene.

Here are the observed proportions where set an estimate of equal across all genes by averaging the observed proportions across all A, C, G, T (i.e. as if the mucelotides are in consistent proportion across all genes):

```{r}
#Find letter frequency
letterFrq = vapply(staph, letterFrequency, FUN.VALUE = numeric(4),
         letters = "ACGT", OR = 0)
colnames(letterFrq) = paste0("gene", seq(along = staph))
#Compute frequencies in first 10 genes and convert to proportions
tab10 = letterFrq[, 1:10]
computeProportions = function(x) { x/sum(x) }
prop10 = apply(tab10, 2, computeProportions)
round(prop10, digits = 2)
p0 = rowMeans(prop10)
p0
```

We find the expected probabilities by multiply the mean proportions for each nucleotide with the total count for each gene. i.e. This is the way the observed counts would divide for each gene if the proportion was equal across all genes

```{r}
cs = colSums(tab10)
cs
expectedtab10 = outer(p0, cs, FUN = "*")
round(expectedtab10)
```

Make a random table with observed column counts if generated from a multinomial with our null proportion spread (i.e. equal across all genes)

```{r}
randomtab10 = sapply(cs, function(s) { rmultinom(1, s, p0) } )
all(colSums(randomtab10) == cs)
```

Repeat this 1000 times to see how often we get a chi-squared value more extreme than we observed.

```{r}
stat = function(obsvd, exptd = 20 * pvec) {
   sum((obsvd - exptd)^2 / exptd)
}
B = 1000
simulstat = replicate(B, {
  randomtab10 = sapply(cs, function(s) { rmultinom(1, s, p0) })
  stat(randomtab10, expectedtab10)
})
S1 = stat(tab10, expectedtab10)
sum(simulstat >= S1)
hist(simulstat, col = "lavender", breaks = seq(0, 75, length.out=50))
abline(v = S1, col = "red")
abline(v = quantile(simulstat, probs = c(0.95, 0.99)),
       col = c("darkgreen", "blue"), lty = 2)
```

It happens 0 times! This is good reason to reject that it's multinomial with equal proportions across all genes.

## 2.6 The $\chi^2$ distribution

### 2.6.1 Intermezzo: quantiles and the quantile-quantile plot


### Q 2.10
Compare quantiles of actual chi-squared test statistics vs our randomly generated chi-squared values with 30 ($=10\times(4-1)$) df.
```{r}
qs = ppoints(100)
par(mfrow=c(1,2))
hist(quantile(simulstat, qs), main = "Test stats under H0 Multinomial")
hist(quantile(qchisq(qs, df = 30), qs), main = "Randomly generated chi-squared")
dev.off()
```

QQ-Plot comparing the two distributions:

```{r}
qqplot(quantile(simulstat, qs),quantile(qchisq(qs, df = 30), qs))
```

This justifies that the test statistic for whether it follows the distribution is $\chi^2_{(30)}$.

### Q 2.11

Median / Second quartile

### Q 2.12

Weighted average of order statistics is how R computes quantiles

Text's qq-plot:

```{r}
qqplot(qchisq(ppoints(B), df = 30), simulstat, main = "",
       xlab = expression(chi[nu==30]^2), asp = 1, cex = 0.5, pch = 16)
abline(a = 0, b = 1, col = "red")
```

## 2.7 Chargaff's Rule

```{r}
load(here("data", "ChargaffTable.RData"))
ChargaffTable

par(mfrow=c(2,4))
barplot(ChargaffTable[1,])
barplot(ChargaffTable[2,])
barplot(ChargaffTable[3,])
barplot(ChargaffTable[4,])
barplot(ChargaffTable[5,])
barplot(ChargaffTable[6,])
barplot(ChargaffTable[7,])
barplot(ChargaffTable[8,])
dev.off()
```

They don't appear to come from the same distribution. 1,3,5,6,7 look the same-ish, 2 looks different and 8 might be it's own or grouped with 2.

\biotip{Chargaff's rule says A and T amounts will be similar while C and G amounts will be similar within one organism but not necessarily between organisms.}

We might make a test statistic
\[(p_C-p_G)^2 + (p_A+pT)^2\]
because this would zero under a null hypothesis that A/T are the same and C/G are the same.

We can test this as a permutation test:

```{r}
#Calculate proposed test stat
statChf = function(x){
  sum((x[, "C"] - x[, "G"])^2 + (x[, "A"] - x[, "T"])^2)
}
chfstat = statChf(ChargaffTable)

#Calculate test stats under a permutation test of relabeling all rows as if there was no pattern
permstat = replicate(100000, {
  permuted = t(apply(ChargaffTable, 1, sample))
  colnames(permuted) = colnames(ChargaffTable)
  statChf(permuted)
})

#p-value
pChf = mean(permstat <= chfstat)
pChf

hist(permstat, breaks = 100, main = "", col = "lavender")
abline(v = chfstat, lwd = 2, col = "red")
```

We only consider lower values because we would never consider a high test statistic as indicative that A/T and C/G were similar.

### 2.7.1 Two categorical Variables

```{r}
HairEyeColor[,,"Female"]
dim(HairEyeColor)
str(HairEyeColor)
```

This is a built in dataset with dimensions $4\times4\times4$

```{r}
load(here("Data", "Deuteranopia.RData"))
Deuteranopia
#Chi-square Test for Independence between and occurrence of color blindness
chisq.test(Deuteranopia)
```

### 2.7.2 A special multinomial: Hardy-Weinberg equilibrium

\biotip{Suppose two Allelles M and N. M has overall frequency $p$ and N has $q=1-p$. If mating happens at random with independence between frequency of allelle genotype then we get the \textbf{Hardy-Weingberg equilibrium (HWE)}}

\[p_{MM}=p^2, \hspace{1cm} p_{NN}=q^2, \hspace{1cm} p_{MN} = 2pq\]

If they occur with frequencies $n_{ij}$, 

\[p(n_{MM},n_{MN},n_{NN}|p)=\binom{S}{n_{MM},n_{MN},n_{NN}}(p^2)^{n_{MM}}\times(2pq)^{n_{MN}}\times(q^2)^{n_{NN}}\]

\[L(p)=n_{MM}log(p^2)+n_{MN}log(2pq)+n_{NN}log(q^2)\]

which is maximized at

\[p=\dfrac{n_{MM}+n_{MN}/2}{S}\]

Loglikelihood for a dataset of allelles from Tahiti
```{r}
library("HardyWeinberg")
data("Mourant")
Mourant[214:216,]

nMM = Mourant$MM[216]
nMN = Mourant$MN[216]
nNN = Mourant$NN[216]
loglik = function(p, q = 1 - p) {
  2 * nMM * log(p) + nMN * log(2*p*q) + 2 * nNN * log(q)
}
xv = seq(0.01, 0.99, by = 0.01)
yv = loglik(xv)
png(here("Class3","loglikelihoodtahiti.png"))
plot(x = xv, y = yv, type = "l", lwd = 2,
     xlab = "p", ylab = "log-likelihood")
imax = which.max(yv)
abline(v = xv[imax], h = yv[imax], lwd = 1.5, col = "blue")
abline(h = yv[imax], lwd = 1.5, col = "purple")
```

Expected values of proportions under Herdy-Weinberg equilibrium

```{r}
#af is a function from HardyWeinberg package to calculate predicted proportions
phat  =  af(c(nMM, nMN, nNN))
phat
pMM   =  phat^2
qhat  =  1 - phat
pHW = c(MM = phat^2, MN = 2*phat*qhat, NN = qhat^2)
sum(c(nMM, nMN, nNN)) * pHW
```
This graph shows confidence intervals for the Hardy-Weinberg Equilibrium
```{r}
pops = c(1, 69, 128, 148, 192)
genotypeFrequencies = as.matrix(Mourant[, c("MM", "MN", "NN")])
HWTernaryPlot(genotypeFrequencies[pops, ],
        markerlab = Mourant$Country[pops],
        alpha = 0.0001, curvecols = c("red", rep("purple", 4)),
        mcex = 0.75, vertex.cex = 1)
```

### 2.7.3 

Can't download seqLogo package
<!--
# ```{r}
# library("seqLogo")
# load(here("Class3","kozak.RData"))
# kozak
# ```
--->

### 2.9.1

```{r}
haplo6=read.table(here("Data","haplotype6.txt"), header = TRUE)
haplo6
```
```{r}
#histogram of y's that are binomial but the probabilities are generated using beta's
rtheta = rbeta(100000, 50, 350)
y = vapply(rtheta, function(th) {
  rbinom(1, prob = th, size = 300)
}, numeric(1))
hist(y, breaks = 50, col = "orange", main = "", xlab = "")
```
\alert{Why 90 610?}
```{r}
#all theta's that had y==40 with the theoretical density overtop 
thetaPostEmp = rtheta[ y == 40 ]
hist(thetaPostEmp, breaks = 40, col = "chartreuse4", main = "",
  probability = TRUE, xlab = expression("posterior"~theta))
densPostTheory  =  dbeta(thetas, 90, 610)
lines(thetas, densPostTheory, type="l", lwd = 3)
```
Show that this agrees.
```{r}
mean(thetaPostEmp)
dtheta = thetas[2]-thetas[1]
sum(thetas * densPostTheory * dtheta)
```

```{r}
thetaPostMC = rbeta(n = 1e6, 90, 610)
mean(thetaPostMC)
qqplot(thetaPostMC, thetaPostEmp, type = "l", asp = 1)
abline(a = 0, b = 1, col = "blue")
```

```{r}
densPost2 = dbeta(thetas, 115, 735)
mcPost2   = rbeta(1e6, 115, 735)

sum(thetas * densPost2 * dtheta)  # mean, by numeric integration
mean(mcPost2)                     # mean, by MC
thetas[which.max(densPost2)]      # MAP estimate
```

### Q2.20
\alert{WHAT DO HERE?}

Posterior Credibility Interval

```{r}
quantile(mcPost2, c(0.025, 0.975))
```

## 2.10 Example: occurrence of a nucelotide pattern in a genome

```{r}
library("Biostrings")
library("BSgenome.Ecoli.NCBI.20080805")
Ecoli
shineDalgarno = "AGGAGGT"
ecoli = Ecoli$NC_010473
```
## 2.13 EXercises

### 2.1

```{r}
m<-rbinom(1000,1000,0.0001)
gfm = goodfit(m, "binomial")
rootogram(gfm, xlab = "", rect_gp = gpar(fill = "chartreuse"))
```


### 2.2

```{r}
max.unif<-function(n){
  max(runif(n,0,7))
}

max.distr<-apply(as.matrix(seq(1:100)),1,max.unif)
hist(max.distr)

likelihoodunif<-function(theta,n=25){
  theta^n
}

thetas<-seq(from = 0, to = 7, by=0.001)
likelihood<-apply(as.matrix(thetas),1,likelihoodunif)
max.likelihood<-thetas[which.max(likelihood)]
max.likelihood
```

The likelihood function is:

\[P(\theta|x_1,x_2,...,x_n)=P(X_1<\theta)P(X_2<\theta)\times...\times P(X_n<\theta)=\theta^n\]

As this is an increasing function in $\theta$ on the range (0,7), it is maximized at 7. So $\hat{\theta}=7$.


### 2.3

```{r}
mtb = read.table(here("Data","M_tuberculosis.txt"), header = TRUE)
head(mtb, n = 4)

pro  =  mtb[ mtb$AmAcid == "Pro", "Number"]
pro/sum(pro)

#a
table(mtb$AmAcid)
table(mtb$Codon)

```

(b) Percentage of total number multiplied by 1000

(c)

```{r}
chisq<-function(x,p=rep(1/length(x))){
  ((x-1000*p)/(1000*p))^2
}
stats<-apply(as.matrix(mtb$PerThous),1,chisq)
maxstat<-as.character(mtb[which.max(stats),1])
maxstat
```

### 2.4


### 2.5